import os
import cv2
import torch
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from torchvision import transforms
import torch.nn.functional as F
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import sys

# GenConViT Î™®Îç∏ importÎ•º ÏúÑÌïú Í≤ΩÎ°ú Ï∂îÍ∞Ä
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from model.pred_func import load_genconvit, df_face, df_face_from_folder
from model.config import load_config

# ÏÑ§Ï†ï Î°úÎìú
config = load_config()

# Ï†ÄÏû• Ìè¥Îçî ÏÑ§Ï†ï (ÌòÑÏû¨ ÏûëÏóÖ ÎîîÎ†âÌÜ†Î¶¨ Í∏∞Ï§Ä)
save_path = "result/gradcam_outputs"
os.makedirs(save_path, exist_ok=True)

# Ï†ÑÏ≤òÎ¶¨ (GenConViT Î™®Îç∏Ïóê ÎßûÍ≤å ÏàòÏ†ï)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225])
])

# GenConViT Î™®Îç∏ Î°úÎìú
def load_model():
    """GenConViT Î™®Îç∏ÏùÑ Î°úÎìúÌï©ÎãàÎã§."""
    # CUDA ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏
    if torch.cuda.is_available():
        try:
            # CUDA Ìò∏ÌôòÏÑ± ÌÖåÏä§Ìä∏
            test_tensor = torch.randn(1, 3, 224, 224).cuda()
            test_result = torch.nn.functional.relu(test_tensor)
            del test_tensor, test_result
            torch.cuda.empty_cache()
            device = "cuda"
            print(f"üñ•Ô∏è Using device: {device}")
        except Exception as e:
            print(f"‚ö†Ô∏è CUDA test failed: {e}")
            print("üîÑ Falling back to CPU mode")
            device = "cpu"
    else:
        device = "cpu"
    
    print(f"üñ•Ô∏è Using device: {device}")
    
    # Î™®Îç∏ Í∞ÄÏ§ëÏπò ÌååÏùº Í≤ΩÎ°ú ÏÑ§Ï†ï (ÌôïÏû•Ïûê Ï†úÍ±∞ - genconvit.pyÏóêÏÑú ÏûêÎèô Ï∂îÍ∞Ä)
    ed_weight = "genconvit_ed_inference"
    vae_weight = "genconvit_vae_inference"
    net = "genconvit"
    fp16 = False
    
    try:
        print("üîß Loading GenConViT model...")
        print(f"üîç Loading weights from:")
        print(f"   - ED: {ed_weight} (will be loaded as weight/{ed_weight}.pth)")
        print(f"   - VAE: {vae_weight} (will be loaded as weight/{vae_weight}.pth)")
        
        # Í∞ÄÏ§ëÏπò ÌååÏùº Ï°¥Ïû¨ ÌôïÏù∏ (ÌôïÏû•Ïûê Ìè¨Ìï®)
        ed_weight_path = f"weight/{ed_weight}.pth"
        vae_weight_path = f"weight/{vae_weight}.pth"
        
        if not os.path.exists(ed_weight_path):
            print(f"‚ùå ED weight file not found: {ed_weight_path}")
            return None, device
        if not os.path.exists(vae_weight_path):
            print(f"‚ùå VAE weight file not found: {vae_weight_path}")
            return None, device
            
        print(f"‚úÖ Weight files found:")
        print(f"   - ED: {ed_weight_path}")
        print(f"   - VAE: {vae_weight_path}")
            
        model = load_genconvit(config, net, ed_weight, vae_weight, fp16)
        model.to(device)
        model.eval()
        print("‚úÖ Model loaded successfully!")
        return model, device
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        import traceback
        traceback.print_exc()
        return None, device

# Î™®Îç∏Í≥º ÎîîÎ∞îÏù¥Ïä§ Î°úÎìú
model, device = load_model()

# GradCAM hookÏö© Ï†ÄÏû• Í≥µÍ∞Ñ
features = []
gradients = []

def forward_hook(module, input, output):
    features.append(output)

def backward_hook(module, grad_input, grad_output):
    if grad_output and len(grad_output) > 0:
        gradients.append(grad_output[0])

# GenConViT Î™®Îç∏Ïùò ÌÉÄÍ≤ü Î†àÏù¥Ïñ¥ ÏÑ§Ï†ï
def setup_hooks():
    """GenConViT Î™®Îç∏Ïóê hookÏùÑ ÏÑ§Ï†ïÌï©ÎãàÎã§."""
    global target_layer
    
    # Î™®Îç∏Ïù¥ Î°úÎìúÎêòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞
    if model is None:
        print("‚ùå Error: Model not loaded. Cannot setup hooks.")
        return False
    
    # GenConViT Î™®Îç∏Ïùò Ï†ÅÏ†àÌïú Î†àÏù¥Ïñ¥Î•º ÌÉÄÍ≤üÏúºÎ°ú ÏÑ§Ï†ï
    target_layer = None
    
    # 1. ED Î™®Îç∏Ïùò Ï§ëÍ∞Ñ ÌäπÏßï Îßµ Î†àÏù¥Ïñ¥ Ï∞æÍ∏∞ (GradCAMÏóê ÏµúÏ†Å)
    if hasattr(model, 'model_ed'):
        weight_layers = []
        for name, module in model.model_ed.named_modules():
            if hasattr(module, 'weight'):
                weight_layers.append((name, module))
        
        if weight_layers:
            target_idx = -2 if len(weight_layers) > 1 else -1
            target_name, target_layer = weight_layers[target_idx]
            target_layer.register_forward_hook(forward_hook)
            target_layer.register_backward_hook(backward_hook)
        else:
            target_layer = list(model.model_ed.modules())[-1]
    
    # 2. VAE Î™®Îç∏Ïùò classifier Î†àÏù¥Ïñ¥ Ï∞æÍ∏∞
    if target_layer is None and hasattr(model, 'model_vae'):
        if hasattr(model.model_vae, 'classifier'):
            target_layer = model.model_vae.classifier
        elif hasattr(model.model_vae, 'fc'):
            target_layer = model.model_vae.fc
    
    # 3. Í∏∞Î≥∏ Î™®Îç∏Ïùò ÎßàÏßÄÎßâ Î†àÏù¥Ïñ¥ ÏÇ¨Ïö©
    if target_layer is None:
        target_layer = list(model.modules())[-1]
    
    try:
        if target_layer is not None:
            return True
        else:
            return False
    except Exception as e:
        return False

# Hook ÏÑ§Ï†ï
if not setup_hooks():
    # Ìè¥Î∞±: Ïó¨Îü¨ Î†àÏù¥Ïñ¥Ïóê hook Îì±Î°ù ÏãúÎèÑ
    try:
        global target_layer
        
        # 1. ED Î™®Îç∏Ïùò Ï§ëÍ∞Ñ Î†àÏù¥Ïñ¥Ïóê hook Îì±Î°ù
        if hasattr(model, 'model_ed'):
            ed_modules = list(model.model_ed.modules())
            target_idx = -3 if len(ed_modules) >= 3 else -2
            target_layer = ed_modules[target_idx]
            
            if hasattr(target_layer, 'weight'):
                target_layer.register_forward_hook(forward_hook)
                target_layer.register_backward_hook(backward_hook)
        else:
            # 2. Ï†ÑÏ≤¥ Î™®Îç∏Ïùò Ï§ëÍ∞Ñ Î†àÏù¥Ïñ¥Ïóê hook Îì±Î°ù
            all_modules = list(model.modules())
            target_idx = len(all_modules) // 2
            target_layer = all_modules[target_idx]
            
            if hasattr(target_layer, 'weight'):
                target_layer.register_forward_hook(forward_hook)
                target_layer.register_backward_hook(backward_hook)
    except Exception as e:
        pass

# GenConViT Î™®Îç∏Ïö© GradCAM Í≥ÑÏÇ∞
def compute_gradcam(input_tensor):
    """GenConViT Î™®Îç∏Ïóê ÎßûÎäî GradCAMÏùÑ Í≥ÑÏÇ∞Ìï©ÎãàÎã§."""
    features.clear()
    gradients.clear()

    try:
        input_tensor.requires_grad_(True)
        input_tensor = input_tensor.to(device)

        # GenConViT Î™®Îç∏Ïùò forward pass Ïã§Ìñâ
        model_output = model(input_tensor)
        
        # Î™®Îç∏ Ï∂úÎ†• Ï≤òÎ¶¨ (GenConViTÎäî Î∂ÑÎ•ò Í≤∞Í≥ºÎ•º Î∞òÌôò)
        if isinstance(model_output, tuple):
            output = model_output[0]  # Ï≤´ Î≤àÏß∏ ÏöîÏÜåÍ∞Ä Î∂ÑÎ•ò Í≤∞Í≥º
        else:
            output = model_output
        
        # ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§ Í≤∞Ï†ï (prediction.pyÏôÄ ÎèôÏùºÌïú Î∞©Ïãù)
        if output.dim() == 2:
            # [batch_size, num_classes] ÌòïÌÉú
            # sigmoid Ï†ÅÏö© ÌõÑ ÌôïÎ•†Ïù¥ ÎÜíÏùÄ ÌÅ¥ÎûòÏä§ ÏÑ†ÌÉù
            probs = torch.sigmoid(output)
            # ÏßÅÏ†ë Ïù∏Îç±Ïã±ÏúºÎ°ú ÏïàÏ†ÑÌïòÍ≤å Ï≤òÎ¶¨
            fake_prob = probs[0, 0].item()
            real_prob = probs[0, 1].item()
            class_idx = 0 if fake_prob > real_prob else 1
            target_output = output[0, class_idx]
        elif output.dim() == 1:
            # [num_classes] ÌòïÌÉú
            probs = torch.sigmoid(output)
            class_idx = 0 if probs[0].item() > probs[1].item() else 1
            target_output = output[class_idx]
        else:
            class_idx = 0
            target_output = output.flatten()[0]
        
        model.zero_grad()
        
        if target_output.dim() > 0:
            target_output = target_output.squeeze()
        
        target_output.backward()
        
        if len(features) == 1 and len(gradients) == 1:
            try:
                fmap = features[0].detach()
                grads = gradients[0].detach()
                
                if fmap.shape == grads.shape:
                    
                    # ÌëúÏ§Ä Grad-CAM Í≥ÑÏÇ∞ Î°úÏßÅ
                    if grads.dim() >= 4 and fmap.dim() >= 4:
                        # 4D ÌÖêÏÑú: [batch, channels, height, width]
                        weights = grads.mean(dim=(2, 3), keepdim=True)
                        cam = (weights * fmap).sum(dim=1, keepdim=True)
                    elif grads.dim() == 2 and fmap.dim() == 2:
                        # 2D ÌÖêÏÑú: [batch, features] - 1D ÌäπÏßïÏùÑ 2DÎ°ú Î≥ÄÌôò
                        batch_size, num_features = fmap.shape
                        spatial_size = int(np.sqrt(num_features))
                        if spatial_size * spatial_size != num_features:
                            spatial_size = int(np.sqrt(num_features)) + 1
                            target_size = spatial_size * spatial_size
                            fmap_padded = torch.zeros(batch_size, target_size, device=fmap.device, dtype=fmap.dtype)
                            grads_padded = torch.zeros(batch_size, target_size, device=grads.device, dtype=grads.dtype)
                            fmap_padded[:, :num_features] = fmap
                            grads_padded[:, :num_features] = grads
                            fmap = fmap_padded
                            grads = grads_padded
                        
                        fmap_2d = fmap.view(batch_size, 1, spatial_size, spatial_size)
                        grads_2d = grads.view(batch_size, 1, spatial_size, spatial_size)
                        weights = grads_2d.mean(dim=(2, 3), keepdim=True)
                        cam = (weights * fmap_2d).sum(dim=1, keepdim=True)
                    else:
                        weights = grads.mean(dim=tuple(range(2, grads.dim())), keepdim=True)
                        cam = (weights * fmap).sum(dim=1, keepdim=True)
                else:
                    return None, output, None

                cam = F.relu(cam)
                
                # CAM Ï∞®Ïõê ÌôïÏù∏ Î∞è ÏïàÏ†ÑÌïú Î≥¥Í∞Ñ
                if cam.dim() == 4:
                    cam = cam.squeeze(1)
                elif cam.dim() == 2:
                    cam = cam.unsqueeze(0)
                
                if cam.dim() == 3 and cam.shape[1] > 1 and cam.shape[2] > 1:
                    cam = F.interpolate(cam.unsqueeze(1), size=(224, 224), mode='bilinear', align_corners=False)
                    cam = cam.squeeze(1)
                else:
                    return None, output, None
                
                cam = cam.squeeze().cpu().numpy()

                cam -= cam.min()
                cam /= (cam.max() + 1e-8)
                
                return cam, output, fmap
            except Exception as e:
                return None, output, None
        else:
            return None, output, None
            
    except Exception as e:
        return None, None, None

# GradCAM ÏãúÍ∞ÅÌôî (ÏòàÏ∏° Í≤∞Í≥º ÌÖçÏä§Ìä∏ Ï∂îÍ∞Ä)
def visualize_gradcam(cam, image_pil, save_path, prediction_text):
    """GradCAM Í≤∞Í≥ºÎ•º ÏãúÍ∞ÅÌôîÌïòÍ≥† Ï†ÄÏû•Ìï©ÎãàÎã§."""
    if cam is None:
        print("‚ö†Ô∏è Warning: CAM is None, skipping visualization")
        return
        
    # ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ ÌöçÎìù
    W, H = image_pil.size

    # cam Ï†ïÍ∑úÌôî
    cam = np.maximum(cam, 0)
    cam = cam - cam.min()
    cam = cam / (cam.max() + 1e-8)
    cam = np.uint8(255 * cam)

    # Í≥†Ìï¥ÏÉÅÎèÑ Î≥¥Í∞Ñ
    cam_resized = cv2.resize(cam, (W, H), interpolation=cv2.INTER_CUBIC)
    heatmap = cv2.applyColorMap(cam_resized, cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)

    # Ïù¥ÎØ∏ÏßÄÏôÄ ÌòºÌï©
    image = np.array(image_pil)
    overlay = 0.5 * image + 0.5 * heatmap
    overlay = np.uint8(np.clip(overlay, 0, 255))

    # PIL ImageÎ°ú Î≥ÄÌôòÌïòÏó¨ ÌÖçÏä§Ìä∏ Ï∂îÍ∞Ä
    overlay_pil = Image.fromarray(overlay)
    draw = ImageDraw.Draw(overlay_pil)
    
    try:
        # Windows ÌôòÍ≤ΩÏóê ÎßûÎäî Ìè∞Ìä∏ ÏÑ§Ï†ï
        if os.name == 'nt':  # Windows
            font = ImageFont.truetype("arial.ttf", 30)
        else:  # Linux/Mac
            font = ImageFont.truetype("/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf", 40)
    except IOError:
        font = ImageFont.load_default()

    # ÌÖçÏä§Ìä∏ ÏúÑÏπò ÏÑ§Ï†ï (Ïòà: Ï¢åÏ∏° ÏÉÅÎã®)
    text_position = (10, 10)
    text_color = (255, 255, 255)  # Ìù∞ÏÉâ

    draw.text(text_position, prediction_text, font=font, fill=text_color)
    overlay_pil.save(save_path)

# Feature Map PCA ÏãúÍ∞ÅÌôî
def visualize_featuremap_pca(feature_map, image_pil, save_path):
    """ÌäπÏßï ÎßµÏùò PCA Í≤∞Í≥ºÎ•º ÏãúÍ∞ÅÌôîÌï©ÎãàÎã§."""
    if feature_map is None:
        print("‚ö†Ô∏è Warning: Feature map is None, skipping PCA visualization")
        return
        
    fmap = feature_map.squeeze().cpu().numpy()  # shape: [C, H, W]
    C, H, W = fmap.shape

    # Flatten and apply PCA
    fmap_flat = fmap.reshape(C, -1).T  # shape: [H*W, C]
    pca = PCA(n_components=1)
    pc1 = pca.fit_transform(fmap_flat).reshape(H, W)

    pc1 -= pc1.min()
    pc1 /= (pc1.max() + 1e-8)
    pc1 = np.uint8(255 * pc1)

    # Upsample to original image size
    cam_resized = cv2.resize(pc1, image_pil.size, interpolation=cv2.INTER_CUBIC)
    heatmap = cv2.applyColorMap(cam_resized, cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)

    overlay = 0.5 * np.array(image_pil.resize(image_pil.size)) + 0.5 * heatmap
    overlay = np.uint8(np.clip(overlay, 0, 255))
    Image.fromarray(overlay).save(save_path)

# ÏñºÍµ¥ Í∏∞Î∞ò Ï≤òÎ¶¨ Ìï®Ïàò
def process_video(video_path, frame_interval=15, output_dir=save_path):
    """ÎπÑÎîîÏò§Î•º Ï≤òÎ¶¨ÌïòÏó¨ GradCAMÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§."""
    if model is None:
        print("‚ùå Error: Model not loaded. Cannot process video.")
        return
        
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        face_data = df_face(video_path, frame_interval)
        
        if len(face_data) == 0:
            return
        
        for frame_idx, face_tensor in enumerate(face_data):
            try:
                # face_tensorÎäî Ïù¥ÎØ∏ Ï†ÑÏ≤òÎ¶¨Îêú ÌÖêÏÑú
                # prediction.pyÏôÄ ÎèôÏùºÌïú Î∞©ÏãùÏúºÎ°ú Î™®Îç∏Ïóê ÏûÖÎ†•
                with torch.no_grad():
                    model_output = model(face_tensor.unsqueeze(0).to(device))
                
                # Î™®Îç∏ Ï∂úÎ†• Ï≤òÎ¶¨
                if isinstance(model_output, tuple):
                    output = model_output[0]
                else:
                    output = model_output
                
                if output.dim() == 2:
                    probs = torch.sigmoid(output)
                    fake_prob = probs[0, 0].item()
                    real_prob = probs[0, 1].item()
                else:
                    probs = torch.sigmoid(output)
                    fake_prob = probs[0].item()
                    real_prob = probs[1].item()
                
                pred_label = "FAKE" if fake_prob > real_prob else "REAL"
                prediction_text = f"Pred: {pred_label} (Fake: {fake_prob:.3f}, Real: {real_prob:.3f})"
                
                cam, _, fmap_tensor = compute_gradcam(face_tensor.unsqueeze(0))
                
                if cam is not None:
                    face_img = face_tensor.cpu().numpy()
                    face_img = np.transpose(face_img, (1, 2, 0))
                    face_img = (face_img * 255).astype(np.uint8)
                    pil_img = Image.fromarray(face_img)
                    
                    grad_path = os.path.join(output_dir, f"face_frame_{frame_idx}_gradcam.jpg")
                    visualize_gradcam(cam, pil_img, grad_path, prediction_text)
            except Exception as e:
                continue
        
    except Exception as e:
        pass

# ÏñºÍµ¥ Í∏∞Î∞ò Îã®Ïùº Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ Ìï®Ïàò
def process_single_image(image_path, output_dir=save_path):
    """Îã®Ïùº Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌï¥ GradCAMÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§."""
    if model is None:
        print("‚ùå Error: Model not loaded. Cannot process image.")
        return
        
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # Ïù¥ÎØ∏ÏßÄÎ•º Ìè¥ÎçîÎ°ú Í∞ÑÏ£ºÌïòÏó¨ df_face_from_folder ÏÇ¨Ïö©
        image_folder = os.path.dirname(image_path)
        if not image_folder:
            image_folder = "."
            
        face_data = df_face_from_folder(image_folder, 1)
        
        if len(face_data) == 0:
            return
        
        face_tensor = face_data[0]
        
        with torch.no_grad():
            model_output = model(face_tensor.unsqueeze(0).to(device))
        
        if isinstance(model_output, tuple):
            output = model_output[0]
        else:
            output = model_output
        if output.dim() == 2:
            # [batch_size, num_classes] ÌòïÌÉú
            probs = torch.sigmoid(output)
            # ÏßÅÏ†ë Ïù∏Îç±Ïã±ÏúºÎ°ú ÏïàÏ†ÑÌïòÍ≤å Ï≤òÎ¶¨
            fake_prob = probs[0, 0].item()
            real_prob = probs[0, 1].item()
        else:
            # [num_classes] ÌòïÌÉú
            probs = torch.sigmoid(output)
            fake_prob = probs[0].item()
            real_prob = probs[1].item()
        
        pred_label = "FAKE" if fake_prob > real_prob else "REAL"
        prediction_text = f"Pred: {pred_label} (Fake: {fake_prob:.3f}, Real: {real_prob:.3f})"
        
        # GradCAM Í≥ÑÏÇ∞ (ÏñºÍµ¥ ÌÖêÏÑú ÏÇ¨Ïö©)
        cam, _, fmap_tensor = compute_gradcam(face_tensor.unsqueeze(0))
        
        if cam is not None:
            face_img = face_tensor.cpu().numpy()
            face_img = np.transpose(face_img, (1, 2, 0))
            face_img = (face_img * 255).astype(np.uint8)
            pil_img = Image.fromarray(face_img)
            
            base_name = os.path.splitext(os.path.basename(image_path))[0]
            grad_path = os.path.join(output_dir, f"{base_name}_gradcam.jpg")
            visualize_gradcam(cam, pil_img, grad_path, prediction_text)

    except Exception as e:
        pass

# Ïã§Ìñâ ÏòàÏãú
if __name__ == "__main__":
    if model is not None:
        print("‚úÖ GenConViT GradCAM Tool ready")
        print(f"   Device: {device}")
        print(f"   Output: {save_path}")
        print("\nUsage:")
        print("   from gradcam import process_video, process_single_image")
        print("   process_video('path/to/video.mp4')")
        print("   process_single_image('path/to/image.jpg')")
    else:
        print("‚ùå Model loading failed. Check weight files and configuration.")