import os
import argparse
import json
from time import perf_counter
from datetime import datetime
import cv2
import numpy as np
import torch
from PIL import Image, ImageDraw, ImageFont
from model.pred_func import *
from model.config import load_config

config = load_config()

def parse_prediction_results(y, y_val):
    """ì˜ˆì¸¡ ê²°ê³¼(y, y_val)ë¥¼ íŒŒì‹±í•˜ì—¬ í™•ë¥ ê³¼ ë¡œì§“ê°’ì„ ë°˜í™˜"""
    # ì˜ˆì¸¡ê°’ ì²˜ë¦¬
    if isinstance(y_val, list):
        fake_prob = y_val[0] if len(y_val) > 0 else 0.0
        real_prob = 1 - fake_prob
    else:
        fake_prob = y_val
        real_prob = 1 - fake_prob
    
    # ë¡œì§“ê°’ ì²˜ë¦¬
    if isinstance(y, list):
        fake_logit = y[0] if len(y) > 0 else 0.0
        real_logit = y[1] if len(y) > 1 else -fake_logit
    else:
        fake_logit = y
        real_logit = -y
    
    # ì˜ˆì¸¡ ê²°ê³¼ ê²°ì •
    prediction = "FAKE" if fake_prob > 0.5 else "REAL"
    confidence = fake_prob if fake_prob > 0.5 else real_prob
    
    return {
        'prediction': prediction,
        'confidence': confidence,
        'fake_prob': fake_prob,
        'real_prob': real_prob,
        'fake_logit': fake_logit,
        'real_logit': real_logit,
        'is_fake': fake_prob > 0.5
    }

def safe_execute(func, error_msg="ì˜¤ë¥˜ ë°œìƒ", show_traceback=False):
    """ì•ˆì „í•œ í•¨ìˆ˜ ì‹¤í–‰ í—¬í¼"""
    try:
        return func()
    except Exception as e:
        if show_traceback:
            import traceback
            print(f"{error_msg}: {e}")
            print(traceback.format_exc())
        else:
            print(f"{error_msg}: {e}")
        return None

def generate_gradcam_with_fallback(model, original_frame, df_tensor, target_class, is_video_frame=False):
    """GradCAM ìƒì„± (ì „ì²´ í”„ë ˆì„ â†’ í¬ë¡­ ê¸°ë°˜ í´ë°±)"""
    prefix = "           " if is_video_frame else ""
    
    # ë°©ë²• 1: ì „ì²´ í”„ë ˆì„ ê¸°ë°˜ GradCAM
    gradcam = safe_execute(
        lambda: generate_gradcam_full_frame(model, original_frame, target_class),
        f"{prefix}ì „ì²´ í”„ë ˆì„ GradCAM ìƒì„± ì¤‘ ì˜¤ë¥˜"
    )
    
    if gradcam is not None:
        if not is_video_frame:
            print(f"âœ… ì „ì²´ í”„ë ˆì„ ê¸°ë°˜ GradCAM ìƒì„± ì„±ê³µ!")
        return gradcam
    
    # ë°©ë²• 2: í¬ë¡­ ê¸°ë°˜ GradCAM (í´ë°±)
    if is_video_frame:
        print(f"{prefix}GradCAM: í¬ë¡­ ê¸°ë°˜ ë°©ë²• ì‹œë„...")
    
    gradcam = safe_execute(
        lambda: generate_gradcam_with_hooks_improved(model, df_tensor, target_class),
        f"{prefix}í¬ë¡­ ê¸°ë°˜ GradCAM ìƒì„± ì¤‘ ì˜¤ë¥˜"
    )
    
    if gradcam is not None:
        if is_video_frame:
            print(f"{prefix}GradCAM: âœ… í¬ë¡­ ê¸°ë°˜ ìƒì„± ì„±ê³µ!")
        else:
            print(f"âœ… í¬ë¡­ ê¸°ë°˜ GradCAM ìƒì„± ì„±ê³µ!")
    
    return gradcam

def save_gradcam_visualization(original_frame, gradcam, pred_label, confidence, face_bbox, output_path, is_video_frame=False):
    """GradCAM ì‹œê°í™” ì €ì¥"""
    prefix = "           " if is_video_frame else ""
    
    visualization = safe_execute(
        lambda: create_gradcam_visualization_improved(original_frame, gradcam, pred_label, confidence, face_bbox),
        f"{prefix}GradCAM ì‹œê°í™” ì¤‘ ì˜¤ë¥˜",
        show_traceback=True
    )
    
    if visualization is not None:
        cv2.imwrite(output_path, cv2.cvtColor(visualization, cv2.COLOR_RGB2BGR))
        return True
    return False

def cleanup_gradcam_frames(gradcam_output_dir):
    """ì´ì „ ì˜ìƒì˜ GradCAM í”„ë ˆì„ ì´ë¯¸ì§€ë“¤ì„ ì‚­ì œí•˜ëŠ” í•¨ìˆ˜"""
    import glob
    
    # GradCAM ì´ë¯¸ì§€ ì‚­ì œ
    gradcam_files = glob.glob(os.path.join(gradcam_output_dir, "frame_*_gradcam.jpg"))
    
    for old_file in gradcam_files:
        try:
            os.remove(old_file)
        except:
            pass

def vids(
    ed_weight, vae_weight, root_dir="sample_prediction_data", dataset=None, num_frames=15, net=None, fp16=False
):
    result = set_result()
    r = 0
    f = 0
    count = 0
    
    model = load_genconvit(config, net, ed_weight, vae_weight, fp16)

    for filename in os.listdir(root_dir):
        curr_vid = os.path.join(root_dir, filename)

        try:
            is_vid_folder = is_video_folder(curr_vid)
            if is_video(curr_vid) or is_vid_folder:
                result, accuracy, count, pred = predict(
                    curr_vid,
                    model,
                    fp16,
                    result,
                    num_frames,
                    net,
                    "uncategorized",
                    count,
                    vid_folder=is_vid_folder
                )
                f, r = (f + 1, r) if "FAKE" == real_or_fake(pred[0]) else (f, r + 1)
                print(
                    f"Prediction: {pred[1]} {real_or_fake(pred[0])} \t\tFake: {f} Real: {r}"
                )
            elif is_image(curr_vid):
                # ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬
                result, accuracy, count, pred = predict_image(
                    curr_vid,
                    model,
                    fp16,
                    result,
                    net,
                    "uncategorized",
                    count
                )
                f, r = (f + 1, r) if "FAKE" == real_or_fake(pred[0]) else (f, r + 1)
                print(
                    f"Prediction: {pred[1]} {real_or_fake(pred[0])} \t\tFake: {f} Real: {r}"
                )
            else:
                print(f"Invalid file: {curr_vid}. Please provide a valid video or image file.")

        except Exception as e:
            print(f"An error occurred: {str(e)}")

    return result


def analyze_single_image(
    ed_weight, vae_weight, image_path, net=None, fp16=False, enable_gradcam=False
):
    """ë‹¨ì¼ ì´ë¯¸ì§€ì˜ ë¡œì§“ ë¶„ì„ í•¨ìˆ˜ (GradCAM ì˜µì…˜ ì§€ì›)"""
    try:
        print(f"ğŸ–¼ï¸  ì´ë¯¸ì§€ ë¶„ì„: {os.path.basename(image_path)}")
        
        model = load_genconvit(config, net, ed_weight, vae_weight, fp16)
        
        if enable_gradcam:
            processed_data = df_face_from_image_with_original(image_path)
            if not processed_data:
                print("âŒ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ê²€ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            df_tensor = processed_data['tensor']
            original_frame = processed_data['original_frames'][0]
            face_bbox = processed_data['face_bboxes'][0] if len(processed_data['face_bboxes']) > 0 else None
            print(f"âœ… ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ\n")
        else:
            df = df_face_from_image(image_path)
            if len(df) == 0:
                print("âŒ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            df_tensor = df
            original_frame = None
            face_bbox = None
            print(f"ğŸ“Š ì–¼êµ´ ì¶”ì¶œ ì™„ë£Œ\n")
        
        if fp16:
            df_tensor = df_tensor.half()
        
        y, y_val = pred_vid(df_tensor, model)
        results = parse_prediction_results(y, y_val)
        
        print(f"ğŸ¯ ì˜ˆì¸¡: {results['prediction']} (ì‹ ë¢°ë„: {results['confidence']:.4f})")
        print(f"ğŸ“Š [FAKE: {results['fake_prob']:.4f}, REAL: {results['real_prob']:.4f}] | ë¡œì§“ [{results['fake_logit']:.4f}, {results['real_logit']:.4f}]")
        
        if enable_gradcam and original_frame is not None:
            gradcam_output_dir = os.path.join("result", "gradcam_outputs")
            os.makedirs(gradcam_output_dir, exist_ok=True)
            cleanup_gradcam_frames(gradcam_output_dir)
            
            target_class = torch.tensor(0 if results['is_fake'] else 1).to(df_tensor.device)
            gradcam = generate_gradcam_with_fallback(model, original_frame, df_tensor, target_class, is_video_frame=False)
            
            if gradcam is not None:
                output_path = os.path.join(gradcam_output_dir, f"image_gradcam.jpg")
                save_gradcam_visualization(original_frame, gradcam, results['prediction'], results['confidence'], face_bbox, output_path)
        
        return results
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    finally:
        cleanup_gpu_memory()


def evaluate_single_class(files, expected_label, class_name, model, data_dir, fp16, results):
    """ë‹¨ì¼ í´ë˜ìŠ¤(Real/Fake)ì— ëŒ€í•œ í‰ê°€ ìˆ˜í–‰"""
    print(f"ğŸ” {class_name} ì´ë¯¸ì§€ í‰ê°€ ì¤‘...")
    for i, filename in enumerate(files, 1):
        file_path = os.path.join(data_dir, filename)
        try:
            df = df_face_from_image(file_path)
            
            if len(df) == 0:
                print(f"   {i:3d}/{len(files)}: {filename} âŒ ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨")
                results['failed_detection'] += 1
                results['total'] += 1
                continue
            
            results['successful_detection'] += 1
            
            if fp16:
                df.half()
            
            y, y_val = pred_vid(df, model)
            parsed = parse_prediction_results(y, y_val)
            is_correct = parsed['prediction'] == expected_label
            
            results['predictions'].append({
                'filename': filename,
                'prediction': parsed['prediction'],
                'fake_prob': parsed['fake_prob'],
                'real_prob': parsed['real_prob'],
                'correct': is_correct
            })
            
            if is_correct:
                results['correct'] += 1
                print(f"   {i:3d}/{len(files)}: {filename} âœ… {expected_label} (í™•ë¥ : {parsed['confidence']:.3f})")
            else:
                print(f"   {i:3d}/{len(files)}: {filename} âŒ {parsed['prediction']} (í™•ë¥ : {parsed['confidence']:.3f}) - ì˜¤ë¶„ë¥˜!")
            
            results['total'] += 1
        except Exception as e:
            print(f"   {i:3d}/{len(files)}: {filename} âŒ ì˜¤ë¥˜: {e}")
            results['total'] += 1

def evaluate_model_precision(
    ed_weight, vae_weight, data_dir="sample_prediction_data", net=None, fp16=False
):
    """ëª¨ë¸ì˜ ì •ë°€ë„ë¥¼ í‰ê°€í•˜ëŠ” í•¨ìˆ˜"""
    print("ğŸ¯ GenConViT ëª¨ë¸ ì •ë°€ë„ í‰ê°€ ì‹œì‘")
    print("=" * 60)
    
    model = load_genconvit(config, net, ed_weight, vae_weight, fp16)
    
    results = {
        'real': {'correct': 0, 'total': 0, 'predictions': [], 'failed_detection': 0, 'successful_detection': 0},
        'fake': {'correct': 0, 'total': 0, 'predictions': [], 'failed_detection': 0, 'successful_detection': 0}
    }
    
    files = os.listdir(data_dir)
    real_files = sorted([f for f in files if f.startswith('real_') and f.endswith('.png')])
    fake_files = sorted([f for f in files if f.startswith('fake_') and f.endswith('.png')])
    
    print(f"ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:")
    print(f"   - Real ì´ë¯¸ì§€: {len(real_files)}ê°œ")
    print(f"   - Fake ì´ë¯¸ì§€: {len(fake_files)}ê°œ")
    print(f"   - ì´ ì´ë¯¸ì§€: {len(real_files) + len(fake_files)}ê°œ\n")
    
    evaluate_single_class(real_files, "REAL", "Real", model, data_dir, fp16, results['real'])
    print()
    evaluate_single_class(fake_files, "FAKE", "Fake", model, data_dir, fp16, results['fake'])
    
    # ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“Š í‰ê°€ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    # Real í´ë˜ìŠ¤ ì„±ëŠ¥
    real_accuracy = results['real']['correct'] / max(results['real']['successful_detection'], 1) * 100
    real_detection_rate = results['real']['successful_detection'] / max(results['real']['total'], 1) * 100
    
    print(f"ğŸ­ REAL í´ë˜ìŠ¤:")
    print(f"   - ì •í™•ë„: {results['real']['correct']}/{results['real']['successful_detection']} ({real_accuracy:.1f}%)")
    print(f"   - ì–¼êµ´ ê²€ì¶œë¥ : {real_detection_rate:.1f}% ({results['real']['successful_detection']}/{results['real']['total']})")
    print(f"   - ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨: {results['real']['failed_detection']}ê°œ")
    
    # Fake í´ë˜ìŠ¤ ì„±ëŠ¥
    fake_accuracy = results['fake']['correct'] / max(results['fake']['successful_detection'], 1) * 100
    fake_detection_rate = results['fake']['successful_detection'] / max(results['fake']['total'], 1) * 100
    
    print(f"ğŸ­ FAKE í´ë˜ìŠ¤:")
    print(f"   - ì •í™•ë„: {results['fake']['correct']}/{results['fake']['successful_detection']} ({fake_accuracy:.1f}%)")
    print(f"   - ì–¼êµ´ ê²€ì¶œë¥ : {fake_detection_rate:.1f}% ({results['fake']['successful_detection']}/{results['fake']['total']})")
    print(f"   - ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨: {results['fake']['failed_detection']}ê°œ")
    
    # ì „ì²´ ì„±ëŠ¥ (ì–¼êµ´ ê²€ì¶œ ì„±ê³µí•œ ì´ë¯¸ì§€ë§Œìœ¼ë¡œ ê³„ì‚°)
    total_correct = results['real']['correct'] + results['fake']['correct']
    total_successful = results['real']['successful_detection'] + results['fake']['successful_detection']
    total_samples = results['real']['total'] + results['fake']['total']
    overall_accuracy = total_correct / max(total_successful, 1) * 100
    
    print(f"\nğŸ¯ ì „ì²´ ì„±ëŠ¥:")
    print(f"   - ì „ì²´ ì •í™•ë„: {total_correct}/{total_successful} ({overall_accuracy:.1f}%)")
    print(f"   - í‰ê·  ì–¼êµ´ ê²€ì¶œë¥ : {(real_detection_rate + fake_detection_rate) / 2:.1f}%")
    print(f"   - ì´ ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨: {results['real']['failed_detection'] + results['fake']['failed_detection']}ê°œ")
    
    # ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ë¶„ì„
    print(f"\nğŸ” ì˜¤ë¶„ë¥˜ ë¶„ì„:")
    real_misclassified = [p for p in results['real']['predictions'] if not p['correct']]
    fake_misclassified = [p for p in results['fake']['predictions'] if not p['correct']]
    
    print(f"   - REAL â†’ FAKE ì˜¤ë¶„ë¥˜: {len(real_misclassified)}ê°œ")
    if real_misclassified:
        print(f"     ê°€ì¥ í™•ì‹ ë„ ë†’ì€ ì˜¤ë¶„ë¥˜: {max(real_misclassified, key=lambda x: x['fake_prob'])['filename']} (FAKE í™•ë¥ : {max(real_misclassified, key=lambda x: x['fake_prob'])['fake_prob']:.3f})")
    
    print(f"   - FAKE â†’ REAL ì˜¤ë¶„ë¥˜: {len(fake_misclassified)}ê°œ")
    if fake_misclassified:
        print(f"     ê°€ì¥ í™•ì‹ ë„ ë†’ì€ ì˜¤ë¶„ë¥˜: {max(fake_misclassified, key=lambda x: x['real_prob'])['filename']} (REAL í™•ë¥ : {max(fake_misclassified, key=lambda x: x['real_prob'])['real_prob']:.3f})")
    
    # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = os.path.join("result", f"precision_evaluation_{net}_{timestamp}.json")
    
    evaluation_summary = {
        'timestamp': timestamp,
        'model': net,
        'dataset': 'sample_prediction_data',
        'total_samples': total_samples,
        'total_successful_detection': total_successful,
        'overall_accuracy': overall_accuracy,
        'real_accuracy': real_accuracy,
        'fake_accuracy': fake_accuracy,
        'real_detection_rate': real_detection_rate,
        'fake_detection_rate': fake_detection_rate,
        'real_correct': results['real']['correct'],
        'real_total': results['real']['total'],
        'real_successful_detection': results['real']['successful_detection'],
        'fake_correct': results['fake']['correct'],
        'fake_total': results['fake']['total'],
        'fake_successful_detection': results['fake']['successful_detection'],
        'real_failed_detection': results['real']['failed_detection'],
        'fake_failed_detection': results['fake']['failed_detection'],
        'total_failed_detection': results['real']['failed_detection'] + results['fake']['failed_detection'],
        'misclassified_real': len(real_misclassified),
        'misclassified_fake': len(fake_misclassified),
        'detailed_results': results
    }
    
    os.makedirs("result", exist_ok=True)
    with open(result_file, "w", encoding="utf-8") as f:
        json.dump(evaluation_summary, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ìƒì„¸ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {result_file}")
    
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    cleanup_gpu_memory()
    
    return evaluation_summary


def analyze_single_video_frame_by_frame(
    ed_weight, vae_weight, video_path, num_frames=15, net=None, fp16=False, enable_gradcam=False
):
    """ë‹¨ì¼ ë¹„ë””ì˜¤ì˜ í”„ë ˆì„ë³„ ë¡œì§“ ë¶„ì„ í•¨ìˆ˜ (GradCAM ì˜µì…˜ ì§€ì›)"""
    try:
        print(f"ğŸ¬ ë¹„ë””ì˜¤ ë¶„ì„: {os.path.basename(video_path)} ({num_frames}í”„ë ˆì„)")
        
        model = load_genconvit(config, net, ed_weight, vae_weight, fp16)
        
        if not is_video(video_path) and not is_video_folder(video_path):
            print(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ë¹„ë””ì˜¤ íŒŒì¼: {video_path}")
            return None
        
        if enable_gradcam:
            processed_data = df_face_with_original(video_path, num_frames)
            if not processed_data:
                print("âŒ í”„ë ˆì„ì—ì„œ ì–¼êµ´ì„ ê²€ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            df_tensor = processed_data['tensor']
            original_frames = processed_data['original_frames']
            face_bboxes = processed_data['face_bboxes']
            print(f"âœ… {len(df_tensor)}ê°œ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ")
        else:
            if is_video_folder(video_path):
                df = df_face_from_folder(video_path, num_frames)
            else:
                df = df_face(video_path, num_frames)
            
            if len(df) == 0:
                print("âŒ ì–¼êµ´ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            df_tensor = df
            original_frames = None
            face_bboxes = None
            print(f"ğŸ“Š ì¶”ì¶œëœ í”„ë ˆì„ ìˆ˜: {len(df)}\n")
        
        if fp16:
            df_tensor = df_tensor.half()
        
        pred_results = pred_vid_frame_by_frame(df_tensor, model, num_frames)
        
        if enable_gradcam:
            gradcam_output_dir = os.path.join("result", "gradcam_outputs")
            os.makedirs(gradcam_output_dir, exist_ok=True)
            cleanup_gradcam_frames(gradcam_output_dir)
        
        # ê° í”„ë ˆì„ë³„ ê²°ê³¼ ì¶œë ¥
        for i, (logit, prediction) in enumerate(zip(pred_results['frame_logits'], pred_results['frame_predictions'])):
            y_val = prediction if isinstance(prediction, list) else [prediction, 1-prediction]
            y = logit if isinstance(logit, list) else [logit, -logit]
            
            parsed = parse_prediction_results(y, y_val)
            print(f"í”„ë ˆì„ {i+1}: {parsed['prediction']} ({parsed['confidence']:.4f})")
            
            # GradCAM ìƒì„± ë° ì‹œê°í™”
            if enable_gradcam and original_frames and i < len(original_frames):
                single_frame = df_tensor[i:i+1]
                original_frame = original_frames[i]
                face_bbox = face_bboxes[i] if i < len(face_bboxes) else None
                
                target_class = torch.tensor(0 if parsed['is_fake'] else 1).to(single_frame.device)
                gradcam = generate_gradcam_with_fallback(model, original_frame, single_frame, target_class, is_video_frame=True)
                
                if gradcam is not None:
                    output_path = os.path.join(gradcam_output_dir, f"frame_{i+1:02d}_gradcam.jpg")
                    save_gradcam_visualization(original_frame, gradcam, parsed['prediction'], parsed['confidence'], face_bbox, output_path, is_video_frame=True)
        
        # ì „ì²´ ìš”ì•½
        frame_preds = pred_results['frame_predictions']
        avg_fake_prob = sum(p if not isinstance(p, list) else p[0] for p in frame_preds) / len(frame_preds)
        overall_pred = "FAKE" if avg_fake_prob > 0.5 else "REAL"
        overall_conf = avg_fake_prob if avg_fake_prob > 0.5 else (1 - avg_fake_prob)
        fake_frames = sum(1 for p in frame_preds if (p if not isinstance(p, list) else p[0]) > 0.5)
        real_frames = len(frame_preds) - fake_frames
        
        print(f"\nğŸ¯ ì „ì²´ ì˜ˆì¸¡: {overall_pred} (ì‹ ë¢°ë„: {overall_conf:.4f}) | í”„ë ˆì„: {len(frame_preds)}ê°œ (FAKE: {fake_frames}, REAL: {real_frames})")
        
        if enable_gradcam:
            gif_output_dir = os.path.join("result", "gradcam_gif")
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            gif_results = create_gradcam_gif(gradcam_dir=gradcam_output_dir, output_dir=gif_output_dir, video_name=video_name)
            
            if gif_results:
                combined_gif = gif_results.get('combined_gif', '')
                gradcam_gif = gif_results.get('gradcam_gif', '')
                if combined_gif:
                    print(f"\nâœ… GIF ìƒì„±: {os.path.basename(combined_gif)}")
                elif gradcam_gif:
                    print(f"\nâœ… GIF ìƒì„±: {os.path.basename(gradcam_gif)}")
        
        return pred_results
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    finally:
        cleanup_gpu_memory()

def faceforensics(
    ed_weight,
    vae_weight,
    root_dir="FaceForensics++",
    dataset=None,
    num_frames=15,
    net=None,
    fp16=False,
):
    keywords = ["original_sequences/youtube/c40/videos/"]

    compression = ["c40", "c23"]
    folders = ["original", "Deepfakes", "Face2Face", "FaceSwap", "NeuralTextures"]

    model = load_genconvit(config, net, ed_weight, vae_weight, fp16)

    for k in compression:
        keywords = [
            f"original_sequences/youtube/{k}/videos/",
            f"manipulated_sequences/Deepfakes/{k}/videos/",
            f"manipulated_sequences/Face2Face/{k}/videos/",
            f"manipulated_sequences/FaceSwap/{k}/videos/",
            f"manipulated_sequences/NeuralTextures/{k}/videos/",
        ]

        for kw, folder in zip(keywords, folders):
            result = set_result()
            count = 0
            accuracy = 0

            if os.path.isfile(os.path.join("json_file", "ff_file_list.json")):
                with open(os.path.join("json_file", "ff_file_list.json")) as data_file:
                    ff_data = json.load(data_file)

            for ff_file in ff_data:
                curr_vid = os.path.join(root_dir, kw + ff_file + ".mp4")
                klass = "REAL" if folder == "original" else "FAKE"
                label = "FAKE" if folder == "original" else "REAL"
                try:
                    if is_video(curr_vid):
                        result, accuracy, count, _ = predict(
                            curr_vid,
                            model,
                            fp16,
                            result,
                            num_frames,
                            net,
                            klass,
                            count,
                            accuracy,
                            label,
                            compression,
                        )
                    else:
                        print(f"Invalid video file: {curr_vid}. Please provide a valid video file.")

                except Exception as e:
                    print(f"An error occurred: {str(e)}")

    return result


def timit(ed_weight, vae_weight, root_dir="DeepfakeTIMIT", dataset=None, num_frames=15, net=None, fp16=False):
    keywords = ["higher_quality", "lower_quality"]
    result = set_result()
    model = load_genconvit(config, net, ed_weight, vae_weight, fp16)
    count = 0
    accuracy = 0
    i = 0
    for keyword in keywords:
        keyword_folder_path = os.path.join(root_dir, keyword)
        for subfolder_name in os.listdir(keyword_folder_path):
            subfolder_path = os.path.join(keyword_folder_path, subfolder_name)
            if os.path.isdir(subfolder_path):
                # Loop through the AVI files in the subfolder
                for filename in os.listdir(subfolder_path):
                    if filename.endswith(".avi"):
                        curr_vid = os.path.join(subfolder_path, filename)
                        try:
                            if is_video(curr_vid):
                                result, accuracy, count, _ = predict(
                                    curr_vid,
                                    model,
                                    fp16,
                                    result,
                                    num_frames,
                                    net,
                                    "DeepfakeTIMIT",
                                    count,
                                    accuracy,
                                    "FAKE",
                                )
                            else:
                                print(f"Invalid video file: {curr_vid}. Please provide a valid video file.")

                        except Exception as e:
                            print(f"An error occurred: {str(e)}")

    return result


def dfdc(
    ed_weight,
    vae_weight,
    root_dir="deepfake-detection-challenge\\train_sample_videos",
    dataset=None,
    num_frames=15,
    net=None,
    fp16=False,
):
    result = set_result()
    if os.path.isfile(os.path.join("json_file", "dfdc_files.json")):
        with open(os.path.join("json_file", "dfdc_files.json")) as data_file:
            dfdc_data = json.load(data_file)

    if os.path.isfile(os.path.join(root_dir, "metadata.json")):
        with open(os.path.join(root_dir, "metadata.json")) as data_file:
            dfdc_meta = json.load(data_file)
    model = load_genconvit(config, net, ed_weight, vae_weight, fp16)
    count = 0
    accuracy = 0
    for dfdc in dfdc_data:
        dfdc_file = os.path.join(root_dir, dfdc)

        try:
            if is_video(dfdc_file):
                result, accuracy, count, _ = predict(
                    dfdc_file,
                    model,
                    fp16,
                    result,
                    num_frames,
                    net,
                    "dfdc",
                    count,
                    accuracy,
                    dfdc_meta[dfdc]["label"],
                )
            else:
                print(f"Invalid video file: {dfdc_file}. Please provide a valid video file.")

        except Exception as e:
            print(f"An error occurred: {str(e)}")

    return result


def celeb(ed_weight, vae_weight, root_dir="Celeb-DF-v2", dataset=None, num_frames=15, net=None, fp16=False):
    with open(os.path.join("json_file", "celeb_test.json"), "r") as f:
        cfl = json.load(f)
    result = set_result()
    ky = ["Celeb-real", "Celeb-synthesis"]
    count = 0
    accuracy = 0
    model = load_genconvit(config, net, ed_weight, vae_weight, fp16)

    for ck in cfl:
        ck_ = ck.split("/")
        klass = ck_[0]
        filename = ck_[1]
        correct_label = "FAKE" if klass == "Celeb-synthesis" else "REAL"
        vid = os.path.join(root_dir, ck)

        try:
            if is_video(vid):
                result, accuracy, count, _ = predict(
                    vid,
                    model,
                    fp16,
                    result,
                    num_frames,
                    net,
                    klass,
                    count,
                    accuracy,
                    correct_label,
                )
            else:
                print(f"Invalid video file: {vid}. Please provide a valid video file.")

        except Exception as e:
            print(f"An error occurred x: {str(e)}")

    return result

# ì´ë¯¸ì§€ ì˜ˆì¸¡ í•¨ìˆ˜ : ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•œ ë¡œì§“ì„ ì¶œë ¥
def predict_image(
    img_path,
    model,
    fp16,
    result,
    net,
    klass,
    count=0,
    accuracy=-1,
    correct_label="unknown",
    compression=None
):
    count += 1
    print(f"\n\n{str(count)} Loading... {img_path}")

    start_time = perf_counter()

    # ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ì¶”ì¶œ
    df = df_face_from_image(img_path)

    if len(df) == 0:
        print(f"âŒ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ê²€ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
        return result, accuracy, count, [0, 0.5]

    if fp16:
        df.half()
    
    y, y_val = pred_vid(df, model)
    
    result = store_result(
        result, os.path.basename(img_path), y, y_val, klass, correct_label, compression
    )

    if accuracy > -1:
        if correct_label == real_or_fake(y):
            accuracy += 1
        print(
            f"\nPrediction: {y_val} {real_or_fake(y)} \t\t {accuracy}/{count} {accuracy/count}"
        )

    end_time = perf_counter()
    print("\n\n only one image--- %s seconds ---" % (end_time - start_time))
    
    return result, accuracy, count, [y, y_val]

# ì˜ìƒ ì˜ˆì¸¡ í•¨ìˆ˜ : í´ë” ì† ëª¨ë“  ì˜ìƒì— ëŒ€í•œ ë¡œì§“ì„ ì¶œë ¥
def predict(
    vid,
    model,
    fp16,
    result,
    num_frames,
    net,
    klass,
    count=0,
    accuracy=-1,
    correct_label="unknown",
    compression=None,
    vid_folder=None
):
    count += 1
    print(f"\n\n{str(count)} Loading... {vid}")

    start_time = perf_counter()

    # locate the extracted frames of the video if provided.
    if vid_folder:
        df = df_face_from_folder(vid, num_frames)
    else:
        df = df_face(vid, num_frames)  # extract face from the frames

    if fp16:
        df.half()
    
    y, y_val = (
        pred_vid(df, model)
        if len(df) >= 1
        else (torch.tensor(0).item(), torch.tensor(0.5).item())
    )
    result = store_result(
        result, os.path.basename(vid), y, y_val, klass, correct_label, compression
    )

    if accuracy > -1:
        if correct_label == real_or_fake(y):
            accuracy += 1
        print(
            f"\nPrediction: {y_val} {real_or_fake(y)} \t\t {accuracy}/{count} {accuracy/count}"
        )

    end_time = perf_counter()
    print("\n\n only one video--- %s seconds ---" % (end_time - start_time))
    
    return result, accuracy, count, [y, y_val]

# ëª…ë ¹ì–´ ì¸ìì
def gen_parser():
    parser = argparse.ArgumentParser("GenConViT prediction")
    parser.add_argument("--p", type=str, help="video or image path")
    parser.add_argument(
        "--f", type=int, help="number of frames to process for prediction"
    )
    parser.add_argument(
        "--d", type=str, help="dataset type, dfdc, faceforensics, timit, celeb"
    )
    parser.add_argument(
        "--s", help="model size type: tiny, large.",
    )
    parser.add_argument(
        "--e", nargs='?', const='genconvit_ed_inference', default='genconvit_ed_inference', help="weight for ed.",
    )
    parser.add_argument(
        "--v", '--value', nargs='?', const='genconvit_vae_inference', default='genconvit_vae_inference', help="weight for vae.",
    )
    
    parser.add_argument("--fp16", type=str, help="half precision support")
    parser.add_argument("--gradcam", action="store_true", help="GradCAM ì‹œê°í™” í™œì„±í™” (ë‹¨ì¼ íŒŒì¼ ë¶„ì„ ì‹œì—ë§Œ ì‚¬ìš©)")
    parser.add_argument("--evaluate", nargs='?', const="sample_prediction_data", default=None, help="ëª¨ë¸ ì •ë°€ë„ í‰ê°€ (ê¸°ë³¸ê°’: sample_prediction_data, ê²½ë¡œë¥¼ ì§€ì •í•˜ë©´ í•´ë‹¹ í´ë” í‰ê°€)")

    args = parser.parse_args()
    path = args.p if args.p else "sample_prediction_data"
    num_frames = args.f if args.f else 15
    dataset = args.d if args.d else "other"
    fp16 = True if args.fp16 else False
    # ë‹¨ì¼ íŒŒì¼ì¸ì§€ ìë™ ê°ì§€ (--single í”Œë˜ê·¸ ì œê±°)
    single_analysis = os.path.isfile(path) and (is_video(path) or is_image(path)) if args.p else False
    enable_gradcam = args.gradcam
    evaluate_model = args.evaluate is not None
    eval_data_dir = args.evaluate if args.evaluate else "sample_prediction_data"

    net = 'genconvit'
    ed_weight = 'genconvit_ed_inference'
    vae_weight = 'genconvit_vae_inference'

    if args.e and args.v:
        ed_weight = args.e
        vae_weight = args.v
    elif args.e:
        net = 'ed'
        ed_weight = args.e
    elif args.v:
        net = 'vae'
        vae_weight = args.v
    
        
    print(f'\nUsing {net}\n')  
    

    if args.s:
        if args.s in ['tiny', 'large']:
            config["model"]["backbone"] = f"convnext_{args.s}"
            config["model"]["embedder"] = f"swin_{args.s}_patch4_window7_224"
            config["model"]["type"] = args.s
    
    return path, dataset, num_frames, net, fp16, ed_weight, vae_weight, single_analysis, enable_gradcam, evaluate_model, eval_data_dir


def main():
    start_time = perf_counter()
    path, dataset, num_frames, net, fp16, ed_weight, vae_weight, single_analysis, enable_gradcam, evaluate_model, eval_data_dir = gen_parser()
    
    if evaluate_model:
        # ëª¨ë¸ ì •ë°€ë„ í‰ê°€
        print("ğŸ¯ ëª¨ë¸ ì •ë°€ë„ í‰ê°€ ëª¨ë“œ")
        print(f"ğŸ“‚ í‰ê°€ ëŒ€ìƒ í´ë”: {eval_data_dir}")
        result = evaluate_model_precision(
            ed_weight, vae_weight, data_dir=eval_data_dir, net=net, fp16=fp16
        )
    # ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš° ìë™ìœ¼ë¡œ ë‹¨ì¼ íŒŒì¼ ë¶„ì„ ëª¨ë“œë¡œ ì „í™˜
    elif single_analysis:
        # ë‹¨ì¼ íŒŒì¼ í”„ë ˆì„ë³„ ë¡œì§“ ë¶„ì„ (ë¹„ë””ì˜¤ ë˜ëŠ” ì´ë¯¸ì§€)
        if os.path.isfile(path):
            if is_image(path):
                result = analyze_single_image(ed_weight, vae_weight, path, net, fp16, enable_gradcam)
            elif is_video(path):
                result = analyze_single_video_frame_by_frame(ed_weight, vae_weight, path, num_frames, net, fp16, enable_gradcam)
            else:
                print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {path}")
                print("ğŸ’¡ ì§€ì› í˜•ì‹: .mp4, .avi, .mov, .jpg, .jpeg, .png")
        else:
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
            print("ğŸ’¡ ì‚¬ìš©ë²•:")
            print("   ë¹„ë””ì˜¤ ë¡œì§“ë§Œ: python prediction.py --p video_path.mp4 --f 10")
            print("   ë¹„ë””ì˜¤ ë¡œì§“+GradCAM: python prediction.py --p video_path.mp4 --f 10 --gradcam")
            print("   ì´ë¯¸ì§€ ë¡œì§“ë§Œ: python prediction.py --p image_path.jpg")
            print("   ì´ë¯¸ì§€ ë¡œì§“+GradCAM: python prediction.py --p image_path.jpg --gradcam")
    else:
        # ê¸°ì¡´ ë°°ì¹˜ ì²˜ë¦¬ ë¡œì§
        result = (
            globals()[dataset](ed_weight, vae_weight, path, dataset, num_frames, net, fp16)
            if dataset in ["dfdc", "faceforensics", "timit", "celeb"]
            else vids(ed_weight, vae_weight, root_dir=path, dataset=dataset, num_frames=num_frames, net=net, fp16=fp16)
        )

        curr_time = datetime.now().strftime("%B_%d_%Y_%H_%M_%S")
        file_path = os.path.join("result", f"prediction_{dataset}_{net}_{curr_time}.json")

        with open(file_path, "w") as f:
            json.dump(result, f)
    
    end_time = perf_counter()
    print("\n\n--- %s seconds ---" % (end_time - start_time))


if __name__ == "__main__":
    main()